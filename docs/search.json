[
  {
    "objectID": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html",
    "href": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html",
    "title": "shriyan.io",
    "section": "",
    "text": "The Data You Know; The Story You Don’t\n\n\ntoc: true\nbadges: true\ncomments: true\ncategories: [jupyter]\nimage: images/chart-preview.png"
  },
  {
    "objectID": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html#what-is-sdv",
    "href": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html#what-is-sdv",
    "title": "shriyan.io",
    "section": "What is SDV?",
    "text": "What is SDV?\nThe Synthetic Data Vault (SDV) is a Synthetic Data Generation ecosystem of libraries that allows users to generate new Synthetic Data that has the same format and statistical properties as the original dataset.\nThe library can also cater to different nature of data as below: 1. single-table - Used to model single table datasets. 2. multi-table - Used to model relational datasets. 3. timeseries - Used to model time-series datasets.\nFeature Highlights\n\nSynthetic data generators for single tables with the following features:\n\nUsing Copulas and Deep Learning based models.\nHandling of multiple data types and missing data with minimum user input.\nSupport for pre-defined and custom constraints and data validation.\n\nSynthetic data generators for complex multi-table, relational datasets with the following features:\n\nDefinition of entire multi-table datasets metadata with a custom and flexible JSON schema.\nUsing Copulas and recursive modeling techniques.\n\nSynthetic data generators for multi-type, multi-variate timeseries with the following features:\n\nUsing statistical, Autoregressive and Deep Learning models.\nConditional sampling based on contextual attributes."
  },
  {
    "objectID": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html#getting-started-with-sdv",
    "href": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html#getting-started-with-sdv",
    "title": "shriyan.io",
    "section": "Getting started with SDV",
    "text": "Getting started with SDV\npip install sdv"
  },
  {
    "objectID": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html#code",
    "href": "posts/the-synthetic-data-story/2022-09-14-synthetic-data-generation.html#code",
    "title": "shriyan.io",
    "section": "Code",
    "text": "Code\n\nimport pandas as pd\nfrom sdv.timeseries import PAR\nimport altair as alt\n\n/home/sharad/repo/projects/data-glance/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\nLoad synthetic data\n\n\ndf = pd.read_csv(\"../data/synthetic.csv\")\ndf.loc[:, \"date\"] = pd.to_datetime(df.date)\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      websiteName\n      category\n      country\n      state\n      city\n      os\n      device\n      product\n      date\n      count\n    \n  \n  \n    \n      0\n      okaz.com.sa\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      2022-05-01 00:00:00\n      545\n    \n    \n      1\n      okaz.com.sa\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      2022-05-01 01:00:00\n      884\n    \n    \n      2\n      okaz.com.sa\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      2022-05-01 02:00:00\n      708\n    \n    \n      3\n      okaz.com.sa\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      2022-05-01 03:00:00\n      550\n    \n    \n      4\n      okaz.com.sa\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      2022-05-01 04:00:00\n      271\n    \n  \n\n\n\n\n\nLets understand how we go about defining our auto-regressive time series model to model our data. There are 2 key parameters that would specifically define how our model is going to learn from our time series data.\nAs mentioned before about the heirarchical nature of the data, we would define our PAR model parameters according to that:\n\nentity_columns: This uniquely defines the entity for which we want to generate a time series. In our case the entity is not singular i.e we want time series for each unique group comprising of websiteName, category, country, state, city, os, device, product.\nsequence_index: Datetime column for time series reference.\n\n\n\nentity_columns = ['category', 'country', 'state', 'city', 'os', 'device', 'product', 'websiteName']\nsequence_index = 'date'\n\nmodel = PAR(\n            entity_columns=entity_columns,\n            sequence_index=sequence_index,\n           )\n\nFit PAR model on the original data\n\n%%time\nmodel.fit(df)\n\nCPU times: user 28.4 s, sys: 154 ms, total: 28.5 s\nWall time: 11 s\n\n\nConditional Sampling\n\nThere is one key feature that PAR model provides, which we are going to specifically use for our problem, that is instead of generating random samples from the model based on raw data, we can provide specific context in which we want the samples.\nThis can be achieved by defining a dataframe consisting of unique entities for which we want to generate a time-series for. One thing to note here is that, the raw data we provided to the model, has 24 hours of data for each unique entity. So the multiple contexts that we define in the next step, the model is going to output 24 rows for each entity.\n\n\ncontext_columns = ['category', 'country', 'state', 'city', 'os', 'device', 'product', 'websiteName']\ndf_freq = df.groupby(context_columns).date.count().sort_values(ascending=False).reset_index()\nmost_freq_group = df_freq[context_columns].to_dict(orient=\"records\")\n\ncontext = pd.DataFrame(\n   most_freq_group\n)\n\n\ncontext\n\n\n\n\n\n  \n    \n      \n      category\n      country\n      state\n      city\n      os\n      device\n      product\n      websiteName\n    \n  \n  \n    \n      0\n      arts&entertainment\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      1\n      arts&entertainment\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n    \n      2\n      society&culture\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      impulse\n      okaz.com.sa\n    \n    \n      3\n      society&culture\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      4\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n    \n      5\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      impulse\n      okaz.com.sa\n    \n    \n      6\n      society&culture\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      7\n      news\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n    \n      8\n      news\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      impulse\n      okaz.com.sa\n    \n    \n      9\n      news\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      10\n      news\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n    \n      11\n      news\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      impulse\n      okaz.com.sa\n    \n    \n      12\n      news\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      13\n      health&fitness\n      indonesia\n      jawa barat\n      bekasi\n      Android\n      mobile\n      impulse\n      sajiansedap.grid.id\n    \n    \n      14\n      business&finance\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      15\n      business&finance\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n    \n      16\n      business&finance\n      saudi arabia\n      ar riyad\n      riyadh\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      17\n      arts&entertainment\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n    \n      18\n      arts&entertainment\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      RotatingCube\n      okaz.com.sa\n    \n    \n      19\n      society&culture\n      saudi arabia\n      makkah al mukarramah\n      jeddah\n      iOS\n      mobile\n      vibe\n      okaz.com.sa\n    \n  \n\n\n\n\nGenerate synthetic data\n\ndf_synthesized = model.sample(context=context)\n\n\ndf_synthesized.shape\n\n(480, 10)\n\n\n\nAs we passed 20 contexts to the model and we were expecting 24 rows for each context, the size of synthesize data is therfore 20 * 24 = 480\n\n\ndf_synthesized.loc[:, \"group_id\"] = df_synthesized.groupby(['category', 'country', 'state', 'city', 'os', 'device', 'product', 'websiteName']).ngroup().apply(lambda x: str(x) + \"_syn\")\n\ndf.loc[:, \"group_id\"] = df.groupby(['category', 'country', 'state', 'city', 'os', 'device', 'product', 'websiteName']).ngroup().apply(lambda x: str(x) + \"_og\")\n\n\nFor the purpose ofo visualizing the raw and model generated data, we create unique group-ids for both raw(groupid_og) and synthetic(groupid_syn) data\n\n\ndef plot_timeseries(df):\n    # select a point for which to provide details-on-demand\n    label = alt.selection_single(\n        encodings=['x'], # limit selection to x-axis value\n        on='mouseover',  # select on mouseover events\n        nearest=True,    # select data point nearest the cursor\n        empty='none'     # empty selection includes no data points\n    )\n\n    # define our base line chart of stock prices\n    base = alt.Chart(df).mark_line().encode(\n        alt.X('date:T'),\n        alt.Y('count:Q'),\n        alt.Color('group_id:N')\n    )\n\n    return alt.layer(\n        base, # base line chart\n\n        # add a rule mark to serve as a guide line\n        alt.Chart().mark_rule(color='#aaa').encode(\n            x='date:T'\n        ).transform_filter(label),\n\n        # add circle marks for selected time points, hide unselected points\n        base.mark_circle().encode(\n            opacity=alt.condition(label, alt.value(1), alt.value(0))\n        ).add_selection(label),\n\n        # add white stroked text to provide a legible background for labels\n        base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n            text='count:Q'\n        ).transform_filter(label),\n\n        # add text labels for stock prices\n        base.mark_text(align='left', dx=5, dy=-5).encode(\n            text='count:Q'\n        ).transform_filter(label),\n\n        data=df\n    ).properties(\n        width=500,\n        height=400\n    )\n\nGroupwise OG vs Synthetic time-series\n\ndf_vis = pd.concat([df[df.group_id.isin([\"0_og\"])], df_synthesized[df_synthesized.group_id.isin([\"0_syn\"])]], ignore_index=True)\nplot_timeseries(df_vis)\n\n\n\n\n\n\n\ndf_vis = pd.concat([df[df.group_id.isin([\"1_og\"])], df_synthesized[df_synthesized.group_id.isin([\"1_syn\"])]], ignore_index=True)\nplot_timeseries(df_vis)\n\n\n\n\n\n\n\ndf_vis = pd.concat([df[df.group_id.isin([\"2_og\"])], df_synthesized[df_synthesized.group_id.isin([\"2_syn\"])]], ignore_index=True)\nplot_timeseries(df_vis)\n\n\n\n\n\n\n\ndf_vis = pd.concat([df[df.group_id.isin([\"3_og\"])], df_synthesized[df_synthesized.group_id.isin([\"3_syn\"])]], ignore_index=True)\nplot_timeseries(df_vis)\n\n\n\n\n\n\n\ndf_vis = pd.concat([df[df.group_id.isin([\"4_og\"])], df_synthesized[df_synthesized.group_id.isin([\"4_syn\"])]], ignore_index=True)\nplot_timeseries(df_vis)"
  },
  {
    "objectID": "posts/the-synthetic-data-story/index.html",
    "href": "posts/the-synthetic-data-story/index.html",
    "title": "The Synthetic Data Story",
    "section": "",
    "text": "The data you know; the story you don’t"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "shriyan.io",
    "section": "",
    "text": "Data Science\n\n\nML\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\nSharad Shriyan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My current work and interest involves tabular data and computer vision problems."
  }
]