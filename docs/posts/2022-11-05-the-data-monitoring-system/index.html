<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>shriyan.io – index</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">shriyan.io</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About Me</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sharad30"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/sharadshriyan"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">



<section id="monitor-your-data-using-dockerized-postgresql-airflow-apache-superset" class="level1">
<h1>Monitor your data using Dockerized PostgreSQL, Airflow &amp; Apache Superset</h1>
<blockquote class="blockquote">
<p>The Data You Know; The Story You Don’t</p>
</blockquote>
<ul>
<li>toc: true</li>
<li>badges: true</li>
<li>comments: true</li>
<li>categories: [jupyter]</li>
<li>image: images/chart-preview.png</li>
</ul>
<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TL;DR</h2>
<p>In this blogpost I will talk about a data monitoring system that I built to monitor the quality and availibility in real time. The system has an <code>Airflow</code> to schedule jobs, <code>PostgreSQL</code> to store data and <code>Superset</code> to visualize the data and monitor its quality.</p>
<p>Through this system I monitored the data quality, data consistency, data drift etc. This system enables you to take actions like - identifying discrepancies in ETL pipeline if expected data is missing, anomaly in the data that is causing the business objective to fail and many more.</p>
</section>
<section id="steps" class="level2">
<h2 class="anchored" data-anchor-id="steps">Steps</h2>
<ol type="1">
<li><p>I will first setup a list of tasks that will enable me to monitor data. This is done using Airflow where tasks run to gather the data of interest.</p></li>
<li><p>I will store the processed data into a PostgreSQL database.</p></li>
<li><p>The data will be visualized and monitored using Superset dashboard.</p></li>
</ol>
</section>
<section id="what-does-the-high-level-architecture-look-like" class="level2">
<h2 class="anchored" data-anchor-id="what-does-the-high-level-architecture-look-like">What does the high level architecture look like?</h2>
<p><img src="monitoring-system.png" class="img-fluid"></p>
</section>
<section id="setting-up-postgresql-airflow-and-superset" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-postgresql-airflow-and-superset">Setting up PostgreSQL, Airflow and Superset</h2>
<section id="docker-postgresql" class="level3">
<h3 class="anchored" data-anchor-id="docker-postgresql">1. Docker PostgreSQL</h3>
<pre><code>docker pull postgres
docker run --name &lt;name_of_container&gt; -e POSTGRES_USER=&lt;username&gt; -e POSTGRES_PASSWORD=&lt;password&gt; -p 5432:5432 -v /data:/var/lib/postgresql/data -d &lt;db_name&gt;</code></pre>
</section>
<section id="docker-airflow" class="level3">
<h3 class="anchored" data-anchor-id="docker-airflow">2. Docker Airflow</h3>
<p>Run the below instructions inside the repo where your your python code resides.</p>
<pre><code>curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.4.1/docker-compose.yaml'
mkdir -p ./dags ./logs ./plugins
echo -e 'AIRFLOW_UID=$(id -u)' &gt; .env
docker-compose up airflow-init</code></pre>
</section>
<section id="docker-superset" class="level3">
<h3 class="anchored" data-anchor-id="docker-superset">3. Docker Superset</h3>
<pre><code>git clone https://github.com/apache/superset.git
cd superset
docker-compose -f docker-compose-non-dev.yml pull
docker-compose -f docker-compose-non-dev.yml up</code></pre>
</section>
</section>
<section id="how-do-you-go-about-scheduling-a-task-using-airflow" class="level2">
<h2 class="anchored" data-anchor-id="how-do-you-go-about-scheduling-a-task-using-airflow">How do you go about scheduling a task using <code>Airflow</code>?</h2>
<p>According to official documentation: &gt; Apache Airflow is an open-source platform for developing, scheduling, and monitoring batch-oriented workflows.</p>
<p>The below steps ensure that you have an up and running job scheduled at regular intervals:</p>
<ol type="1">
<li>Define a function to fetch data from the API or from S3 or any other source</li>
</ol>
<pre><code>def download_api_data():
    print(f"Fetching data....")
    response = requests.get(&lt;API url&gt;)
    data = response.json()
    print(f"Total number of data: {len(data)}")
    json_object = json.dumps(data, indent=2)
    with open(f"/tmp/pdl_{currency}_hourly.json", "w") as f:
        f.write(json_object)
    print(f"Finished downloading data.....")</code></pre>
<p>The above function fetches data from the API and then stores it as json file for further processing.</p>
<ol start="2" type="1">
<li>Define a function to move downloaded data(json, csv etc.) to PostgreSQL</li>
</ol>
<pre><code>def move_pdl_data_to_postgres(**kwargs):
    currency = kwargs["currency"]
    print(f"Populating for {currency} has started")
    with open(f"/tmp/pdl_{currency}_hourly.json") as f:
        data = json.load(f)
    df = pd.DataFrame(data)

    # Define your preprocessing steps here like typecasting a column according to the Postgresql schema and any other steps specific to your use case

    print("All values created, starting the push to db")
    df.to_sql(name="&lt;name-of-sql-table&gt;", con=engine, index=False, if_exists="append", chunksize=300)</code></pre>
<p>In the above function we load the json data downloaded in step 1 inside a dataframe and then move it to PostgreSQL table, defined in our <code>con</code> parameter of <code>to_sql</code> function.</p>
<ol start="3" type="1">
<li>Define a <code>DAG</code></li>
</ol>
<ul>
<li>DAG object is needed to define how we are going to schedule our various tasks.</li>
<li>Here we pass a string that defines the dag_id, which serves as a unique identifier for your DAG and also description.</li>
<li>We also schedule a DAG using <code>schedule_interval</code> parameter to run it at hourly frequency and also provide start_date of the DAG.</li>
<li>Below is an example of the DAG definition:</li>
</ul>
<pre><code>dag = DAG(
    dag_id="data-migration",
    description="Daily data monitoring pipeline",
    schedule_interval="0 * * * *",
    start_date=datetime(2022, 10, 17),
)</code></pre>
<ol start="4" type="1">
<li>Define <code>PythonOperator</code></li>
</ol>
<ul>
<li>Operators are tasks that define a unit of work to be done.</li>
<li>There are manny different kind of operators that you can play around with in Airflow. But we will stick to <code>PythonOperator</code>, which takes python function as a parameter.</li>
<li>Here we define the <code>task_id</code>, <code>python_callable</code> and above defined <code>dag</code> object.</li>
<li>Below is how we define the <code>PythonOperator</code> object</li>
</ul>
<pre><code>PythonOperator(
            task_id=f"download_json",
            python_callable=download_json,
            dag=dag,
        )</code></pre>
<ol start="5" type="1">
<li>Setup task dependencies</li>
</ol>
<p>Lets say we have 2 PythonOperator defined as 2 tasks and one task is dependent on the other. In our case we first fetch the data from API and then push the data to PostgreSQL. So setting up task dependency kind of becomes and it is defined by using <code>&gt;&gt;</code> operator as follows:</p>
<pre><code>task1 &gt;&gt; task2</code></pre>
<p>Here the Airflow DAG knows that it has to first finish running the <code>task1</code> and then move on to <code>task2</code>. Any failure in task1 will result in termination of the job.</p>
</section>
<section id="what-is-the-airflow-ui-going-to-look-like" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-airflow-ui-going-to-look-like">What is the Airflow UI going to look like?</h2>
<p><img src="airflow-graph.png" class="img-fluid"></p>
<p>The above UI can be accessed after Airflow login and navigating as follows: <code>&lt;DAG-name&gt; &gt; Graph</code>.</p>
<p>The Graph shows you the various tasks that are scheduled to run and each row defines multiple tasks and how each one is dependent on the other i.e Task <code>move_pdl_data_to_postgres_ADA</code> is dependent on <code>download_pdl_json_ADA</code> and hence has to be completed first.</p>
<p>The subsequent rows follow a similar pattern and here we have demonstrated multiple different jobs scheduled inside a single DAG, where each job does the same thing as other, but for different type of data i.e for different bitcoin currencies in our scenario.</p>
</section>
<section id="how-to-visualize-the-raw-data-in-apache-superset" class="level2">
<h2 class="anchored" data-anchor-id="how-to-visualize-the-raw-data-in-apache-superset">How to visualize the raw data in <code>Apache Superset</code>?</h2>
<p><img src="superset-dashboard.png" class="img-fluid"></p>
<ul>
<li>Superset is a data exploration and visualization platform and we are going to leverage it to use it as our frontend for monitoring the data we move to the PostgreSQL at regular intervals.</li>
<li>As seen in the above example dashboard we are doing some sanity check and checking the trend for a bitcoin currency.</li>
<li>So playing around with visualizations specific to your data and problem statement is straight forward in Superset and it comes with a bunch of features.</li>
</ul>
</section>
<section id="what-next" class="level2">
<h2 class="anchored" data-anchor-id="what-next">What next?</h2>
<p>This task can be further expanded in various aspects each from PostgreSQl, Airflow and Superset perspective, by adding more sources of information that we want to monitor in real time and keep adding more tables to our PostgreSQL database, schedule more DAGs in our Airflow container and add more dashboards monitoring the nature of different data.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>